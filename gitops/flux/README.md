* Setup the Gitlab instance either with OIDC or non-OIDC
* Login to Gitlab GUI
* Note the docker-compose files for Gitlab will expose the GUI at port 10443 and SSH at 2224
* On the EKS Admin machine., create the SSH keys for Gitlab that Flux will use
* In my example, I am storing the generated keys as $HOME/.ssh/gitlab
```
# EXPORT THE REQUIRED VARIABLES IN PROFILE
cd $HOME
echo "EKSA_GIT_PRIVATE_KEY=/home/ubuntu/.ssh/gitlab; export EKSA_GIT_PRIVATE_KEY" >> ~/.profile
echo "SSH_KNOWN_HOSTS=/home/ubuntu/.ssh/known_hosts; export SSH_KNOWN_HOSTS" >> ~/.profile
echo "EKSA_GIT_KNOWN_HOSTS=/home/ubuntu/.ssh/known_hosts; export EKSA_GIT_KNOWN_HOSTS" >> ~/.profile
source .profile
```
* Generate SSH keys for Gitlab
```
ssh-keygen -t ecdsa -C "user_admin@your-domain-name" (for azure AD, use the principal name,e.g. ambar@ambaru2ubegmail.onmicrosoft.com)
eval "$(ssh-agent -s)" && ssh-add $EKSA_GIT_PRIVATE_KEY
cat $EKSA_GIT_PRIVATE_KEY.pub
chmod 600 $EKSA_GIT_PRIVATE_KEY
```
* Copy the public key to Gitlab via GUI (User icon > preferences > SSH Keys)
* Now that the public key is in Gitlab, we need to SSH so that it is stored in the ./ssh/known_hosts file
```
ssh -i gitlab git@gitlab1.poc.thecloudgarage.com -p 2224
``` 
* EKSA will use two variables and automatically inject them for FLUX operations (secret creation, connecting to gitlab, etc.)
* Let's export these three variables within the cluster creation script.. Insert the below in the cluster creation script.
* Do not export them outside the script as they bash would not be able to access them
* Also ensure the FluxConfig configuration uses the correct SSH port number in the repositoryUrl for SSH (In my case it's 2224)
* In addition, create an empty repository before-hand with the name specified in the FluxConfig in Cluster's YAML
* Example:
```
---
apiVersion: anywhere.eks.amazonaws.com/v1alpha1
kind: FluxConfig
metadata:
  name: my-flux-config
spec:
    git:
      repositoryUrl: ssh://git@gitlab1.poc.thecloudgarage.com:2224/ambar/flux-test.git
      sshKeyAlgorithm: ecdsa
```
Once the cluster is created, Flux will automatically build the sub-directories in the git repo and commit the initial files. The structure of the directories in gitlab committed by flux look like below

![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/3e379cdb-26b3-4b5b-bb54-dea39c839f2f)

![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/034672ee-a075-4b16-a412-e9b1e7ed725a)

![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/c8b31afd-e57e-4844-9703-59a4a288dc69)

The contents of kustomization.yaml inside flux-system directory

```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: flux-system
resources:
- gotk-components.yaml
- gotk-sync.yaml
patches:
- patch: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: helm-controller
      namespace: flux-system
    spec:
      template:
        spec:
          containers:
          - image: public.ecr.aws/eks-anywhere/fluxcd/helm-controller:v0.37.4-eks-a-65
            name: manager
- patch: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: kustomize-controller
      namespace: flux-system
    spec:
      template:
        spec:
          containers:
          - image: public.ecr.aws/eks-anywhere/fluxcd/kustomize-controller:v1.2.2-eks-a-65
            name: manager
- patch: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: notification-controller
      namespace: flux-system
    spec:
      template:
        spec:
          containers:
          - image: public.ecr.aws/eks-anywhere/fluxcd/notification-controller:v1.2.4-eks-a-65
            name: manager
- patch: |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: source-controller
      namespace: flux-system
    spec:
      template:
        spec:
          containers:
          - image: public.ecr.aws/eks-anywhere/fluxcd/source-controller:v1.2.4-eks-a-65
            name: manager
```
The contents of the gotk-sync.yaml are shown below. gotk-components is a huge 9K lines of code, so omitting from here.. Basically the gotk-sync.yaml is the most important file that implies that any code committed in this git repo will be synced backed to the cluster named flux-test-2
```
# This manifest was generated by flux. DO NOT EDIT.
---
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: flux-system
  namespace: flux-system
spec:
  interval: 1m0s
  ref:
    branch: main
  secretRef:
    name: flux-system
  url: ssh://git@gitlab1.poc.thecloudgarage.com:2224/ambar/flux-test.git
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: flux-system
  namespace: flux-system
spec:
  interval: 10m0s
  path: ./clusters/flux-test-2
  prune: true
  sourceRef:
    kind: GitRepository
    name: flux-system
```
Navigating to other parts of the directory structure

![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/dfe48a66-1e83-468e-8129-8be25587391e)

We can see it generates a kustomization file that refers to the auto-committed EKS-A cluster YAML file

```
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- eksa-cluster.yaml
```
Now we can do two things, manage the cluster by changing the values in the committed file within the repo OR we can create new apps/helm configs, etc... and commit to the repo and those will be deployed automatically in the cluster. Let's try the latter as the earlier use-case is well known. Commit a new deployment file or create it directly via the web-browser in Gitlab. Which sub-directory to use... As one can see from the below visual, the flux gitops controller will continuously scan the sub-directory ./clusters/flux-test-2/ via the got-sync.yaml. So anything new created under this git sub-directory will automatically get deployed on the flux-test-2 cluster

![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/97f8b048-5bcf-40f6-b644-77e7be67bff4)
* Example: 1 Create a demo namespace
```
# We will define a new sub-directory under ./clusters/flux-test-2/ and name it as test-deployments and commit a new file that creates a new namespace.

# To start let's observe the default namespaces

kubectl get ns
NAME                                STATUS   AGE
capi-kubeadm-bootstrap-system       Active   4h12m
capi-kubeadm-control-plane-system   Active   4h12m
capi-system                         Active   4h12m
capv-system                         Active   4h12m
cert-manager                        Active   4h12m
default                             Active   4h19m
eksa-system                         Active   4h13m
etcdadm-bootstrap-provider-system   Active   4h12m
etcdadm-controller-system           Active   4h12m
flux-system                         Active   4h9m
kube-node-lease                     Active   4h19m
kube-public                         Active   4h19m
kube-system                         Active   4h19m
```
* Now create a new sub-directory under the top-level of the repo and call it as deployments, and then create a new file under it named demo-namespace.yaml with the below contents

```
apiVersion: v1
kind: Namespace
metadata:
  name: demo
```
  
![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/f8da276e-bab0-4a87-966c-cead5c69acb1)

Upon committing this new file, we can observe that the flux-controller has picked up the changes via got-sync.yaml and deployed it into the flux-test-2 cluster. Look at the age of the demo namespace
```
 kubectl get ns
NAME                                STATUS   AGE
capi-kubeadm-bootstrap-system       Active   4h40m
capi-kubeadm-control-plane-system   Active   4h40m
capi-system                         Active   4h40m
capv-system                         Active   4h40m
cert-manager                        Active   4h41m
default                             Active   4h47m
demo                                Active   30s
eksa-system                         Active   4h41m
etcdadm-bootstrap-provider-system   Active   4h40m
etcdadm-controller-system           Active   4h40m
flux-system                         Active   4h37m
kube-node-lease                     Active   4h47m
kube-public                         Active   4h47m
kube-system                         Active   4h47m
```
Now let's observe some changes in the cluster by updating the number of worker nodes (we can also change CPU, memory, etc.) There are two ways to go about it
* Preferred method: Perform a change in the cluster YAML file in EKS-A machine and commit it to the gitlab repo. This way the cluster config on the EKS-A machine, the gitlab repo and the actual cluster configuration., all will be in sync
* Alternate method: (just to demonstrate for this writing). Edit the cluster config directly in gitlab and flux will automatically roll out those changes.
As now, we will do this change on the GitLab UI. But before that, let's check the current state of node count
```
kubectl get nodes
NAME                           STATUS   ROLES           AGE     VERSION
flux-test-2-9jx75              Ready    control-plane   4h53m   v1.29.1-eks-61c0bbb
flux-test-2-bzlgb              Ready    control-plane   4h52m   v1.29.1-eks-61c0bbb
flux-test-2-jfqtw              Ready    control-plane   4h51m   v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-6ctn6   Ready    <none>          4h50m   v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-lzrkm   Ready    <none>          4h50m   v1.29.1-eks-61c0bbb
```
Now let's edit the cluster config YAML in Gitlab and change the worker node count from 2 to 3
![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/5c4ce3e0-366d-401f-a00f-ddc7cdd0aa70)
![image](https://github.com/thecloudgarage/eks-anywhere/assets/39495790/7312a6a9-829c-4209-816b-53609bbf8b77)
We can observe that the Flux-controller has picked the gitlab stored template changes and rolled out a new node
```
kubectl get nodes
NAME                           STATUS     ROLES           AGE     VERSION
flux-test-2-9jx75              Ready      control-plane   4h57m   v1.29.1-eks-61c0bbb
flux-test-2-bzlgb              Ready      control-plane   4h56m   v1.29.1-eks-61c0bbb
flux-test-2-jfqtw              Ready      control-plane   4h55m   v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-6ctn6   Ready      <none>          4h53m   v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-bb5fl   NotReady   <none>          16s     v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-lzrkm   Ready      <none>          4h53m   v1.29.1-eks-61c0bbb
```
We will wait for this node to transition from NotReady to Ready
```
 kubectl get nodes
NAME                           STATUS   ROLES           AGE     VERSION
flux-test-2-9jx75              Ready    control-plane   4h58m   v1.29.1-eks-61c0bbb
flux-test-2-bzlgb              Ready    control-plane   4h57m   v1.29.1-eks-61c0bbb
flux-test-2-jfqtw              Ready    control-plane   4h56m   v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-6ctn6   Ready    <none>          4h55m   v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-bb5fl   Ready    <none>          90s     v1.29.1-eks-61c0bbb
flux-test-2-md-0-plfbr-lzrkm   Ready    <none>          4h55m   v1.29.1-eks-61c0bbb
```
In about 90 seconds, the node is up and ready within the cluster. In the same manner, we can upgrade the CPU/Memory or scale in the number of nodes, etc.


# PROBLEM: The below specified method by AWS in the official EKS-A doc did not work
```
cd $HOME/.ssh/
ssh-keyscan -t ecdsa your-gitlab-server-FQDN >> my_eksa_known_hosts (without https or the port number)
```
